{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facemask Detection Datathon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data science libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import os                    # OS module in Python provides a way of using operating system dependent functionality\n",
    "import pandas as pd          # Data analysis and manipultion tool\n",
    "import numpy as np           # Fundamental package for linear algebra and multidimensional arrays\n",
    "import matplotlib.pyplot as plt   # for visualization\n",
    "import cv2                        # Library for image processing\n",
    "import argparse\n",
    "from imutils import paths\n",
    "from tqdm.notebook import tqdm # widget progress bar\n",
    "# Scikit-learn utils..\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.model_selection import train_test_split    # For splitting the data into train and validation set\n",
    "\n",
    "#Deep Learning Tool\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras import models  \n",
    "from keras.models import load_model\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import Activation\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_1.jpg</td>\n",
       "      <td>without_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_2.jpg</td>\n",
       "      <td>without_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_3.jpg</td>\n",
       "      <td>without_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_4.jpg</td>\n",
       "      <td>without_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_5.jpg</td>\n",
       "      <td>without_mask</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename         label\n",
       "0  Image_1.jpg  without_mask\n",
       "1  Image_2.jpg  without_mask\n",
       "2  Image_3.jpg  without_mask\n",
       "3  Image_4.jpg  without_mask\n",
       "4  Image_5.jpg  without_mask"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "training_set_path = path + '\\\\Training_set_face_mask.csv'\n",
    "labels = pd.read_csv(training_set_path)   # loading the labels\n",
    "labels.head()                             # will display the first five rows in labels dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11259</th>\n",
       "      <td>Image_11260.jpg</td>\n",
       "      <td>with_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11260</th>\n",
       "      <td>Image_11261.jpg</td>\n",
       "      <td>with_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11261</th>\n",
       "      <td>Image_11262.jpg</td>\n",
       "      <td>with_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11262</th>\n",
       "      <td>Image_11263.jpg</td>\n",
       "      <td>with_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11263</th>\n",
       "      <td>Image_11264.jpg</td>\n",
       "      <td>with_mask</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename      label\n",
       "11259  Image_11260.jpg  with_mask\n",
       "11260  Image_11261.jpg  with_mask\n",
       "11261  Image_11262.jpg  with_mask\n",
       "11262  Image_11263.jpg  with_mask\n",
       "11263  Image_11264.jpg  with_mask"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.tail()            # will display the last five rows in labels dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting image's filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Image_1.jpg', 'C:\\\\Users\\\\perro\\\\Documents\\\\deep_learning_final\\\\face_mask_detection\\\\train\\\\Image_1.jpg']\n"
     ]
    }
   ],
   "source": [
    "file_paths = [[fname, path + '\\\\train\\\\' + fname] for fname in labels['filename']]\n",
    "print(file_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirming if number of labels is equal to number of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels i.e.  11264 matches the number of filenames i.e.  11264\n"
     ]
    }
   ],
   "source": [
    "# Confirm if number of images is same as number of labels given\n",
    "if len(labels) == len(file_paths):\n",
    "    print('Number of labels i.e. ', len(labels), 'matches the number of filenames i.e. ', len(file_paths))\n",
    "else:\n",
    "    print('Number of labels does not match the number of filenames')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the file_paths to dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>filepaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_1.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_2.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_3.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_4.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_5.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename                                          filepaths\n",
       "0  Image_1.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...\n",
       "1  Image_2.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...\n",
       "2  Image_3.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...\n",
       "3  Image_4.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...\n",
       "4  Image_5.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = pd.DataFrame(file_paths, columns=['filename', 'filepaths'])\n",
    "images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining the labels with the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>filepaths</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_1.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "      <td>without_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_2.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "      <td>without_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_3.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "      <td>without_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_4.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "      <td>without_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_5.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "      <td>without_mask</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename                                          filepaths  \\\n",
       "0  Image_1.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...   \n",
       "1  Image_2.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...   \n",
       "2  Image_3.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...   \n",
       "3  Image_4.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...   \n",
       "4  Image_5.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...   \n",
       "\n",
       "          label  \n",
       "0  without_mask  \n",
       "1  without_mask  \n",
       "2  without_mask  \n",
       "3  without_mask  \n",
       "4  without_mask  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.merge(images, labels, how = 'inner', on = 'filename')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing \n",
    "\n",
    "#### Performing one-hot encoding on the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels_bin = lb.fit_transform(train_data.label) # categorical labels to binary\n",
    "train_data[\"labels_bin\"] = lb.fit_transform(train_data.label) # categorical labels to binary\n",
    "labels_OHE =  to_categorical(labels_bin)  # One-Hot-Encoding for the labels binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>filepaths</th>\n",
       "      <th>label</th>\n",
       "      <th>labels_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_1.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "      <td>without_mask</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_2.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "      <td>without_mask</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_3.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "      <td>without_mask</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_4.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "      <td>without_mask</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_5.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "      <td>without_mask</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename                                          filepaths  \\\n",
       "0  Image_1.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...   \n",
       "1  Image_2.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...   \n",
       "2  Image_3.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...   \n",
       "3  Image_4.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...   \n",
       "4  Image_5.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...   \n",
       "\n",
       "          label  labels_bin  \n",
       "0  without_mask           1  \n",
       "1  without_mask           1  \n",
       "2  without_mask           1  \n",
       "3  without_mask           1  \n",
       "4  without_mask           1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffling input and target for optimum training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9529    0\n",
      "2249    1\n",
      "2071    1\n",
      "2388    1\n",
      "149     1\n",
      "Name: labels_bin, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "x = train_data['filepaths']\n",
    "y = train_data['labels_bin']\n",
    "\n",
    "x, y = shuffle(x, y, random_state=8)\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for Resizing and Reshaping the input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centering_image(img):\n",
    "    \n",
    "    size = [256,256]\n",
    "    #shape:(h×w×t)taking the first2 elements(h,w) and unpacking them appropriately \n",
    "    img_size = img.shape[:2]\n",
    "    \n",
    "    # extracting the excess space for centering.\n",
    "    row = (size[1] - img_size[0]) // 2\n",
    "    col = (size[0] - img_size[1]) // 2\n",
    "    \n",
    "    #creating centered image by taking a 0-matrix and then re-assigning intensities\n",
    "    resized = np.zeros(list(size) + [img.shape[2]], dtype=np.uint8)\n",
    "    resized[row:(row + img.shape[0]), col:(col + img.shape[1])] = img\n",
    "\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image resizing and converting them to an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f66beb054e4409db24d0a493412cdd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11264.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\" \n",
    "TQDM is a progress bar library. \n",
    "Inserting tqdm (or python -m tqdm)between pipes will pass \n",
    "through all stdin to stdout while printing progress to stderr\n",
    "\"\"\"\n",
    "images = []\n",
    "with tqdm(total=len(train_data)) as pbar:\n",
    "    for i, file_path in enumerate(train_data.filepaths.values):\n",
    "        \n",
    "        #read image\n",
    "        img = cv2.imread(file_path,1)\n",
    "        #color order is changed\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        #print(img)\n",
    "\n",
    "        #resize\n",
    "        #converting images to square\n",
    "        if(img.shape[0] > img.shape[1]):\n",
    "            tile_size = (int(img.shape[1]*256/img.shape[0]),256)\n",
    "        else:\n",
    "            tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n",
    "\n",
    "        #centering the images\n",
    "        img = centering_image(cv2.resize(img, dsize=tile_size))\n",
    "\n",
    "        #out put 224*224px \n",
    "        img = img[16:240, 16:240]\n",
    "        images.append(img)\n",
    "        pbar.update(1)\n",
    "\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-Shuffling processed train data and converting to array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = len(y)\n",
    "random_index = np.random.permutation(data_num)\n",
    "\n",
    "x_shuffle = []\n",
    "y_shuffle = []\n",
    "for i in range(data_num):\n",
    "    x_shuffle.append(images[random_index[i]])\n",
    "    y_shuffle.append(y[random_index[i]])\n",
    "    \n",
    "x = np.array(x_shuffle)\n",
    "y = np.array(y_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train val split, oneHotVectorizing categories, input normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (9011, 224, 224, 3)\n",
      "y_train (9011,)\n",
      "########################\n",
      "x_test (2253, 224, 224, 3)\n",
      "y_test (2253,)\n",
      "x_train Shape: (9011, 224, 224, 3) \t x_test Shape: (2253, 224, 224, 3)\n",
      "y_train Shape:  (9011, 2) \t y_test Shape: (2253, 2)\n",
      "image Shape: (224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "#Train val split\n",
    "# partition the data into training and testing splits using 80% of\n",
    "# the data for training and the remaining 20% for testing\n",
    "val_split_num = int(round(0.2*len(y)))\n",
    "\n",
    "x_train = x[val_split_num:]\n",
    "y_train = y[val_split_num:]\n",
    "\n",
    "x_validation = x[:val_split_num]\n",
    "y_validation = y[:val_split_num]\n",
    "\n",
    "print('x_train', x_train.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('########################')\n",
    "print('x_test', x_validation.shape)\n",
    "print('y_test', y_validation.shape)\n",
    "\n",
    "# OneHotVectorizing categories\n",
    "y_train = to_categorical(y_train)\n",
    "y_validation = to_categorical(y_validation)\n",
    "\n",
    "# Input normalization\n",
    "x_train = x_train.astype('float32')\n",
    "x_validation = x_validation.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_validation /= 255\n",
    "\n",
    "print('x_train Shape:', x_train.shape, '\\t x_test Shape:',x_validation.shape)\n",
    "print('y_train Shape: ', y_train.shape, '\\t y_test Shape:',y_validation.shape)\n",
    "print('image Shape:', x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 222, 222, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 109, 109, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 52, 52, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                2768960   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 2,797,730\n",
      "Trainable params: 2,797,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "# CONVOLUTIONAL ARCHITECTURE \n",
    "'''\n",
    "\n",
    "learning_rate = 1e-4\n",
    "epochs = 10\n",
    "\n",
    "model = Sequential()\n",
    "# first layer\n",
    "model.add(Conv2D(32,(3,3), input_shape=(224, 224,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#second layer\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# flatten\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "# print(model.output_shape)\n",
    "# print(model.summary())\n",
    "\n",
    "opt = Adam(lr=learning_rate, decay=learning_rate / epochs)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "#history = model.fit(data,target,epochs=1,validation_split=0.2)\n",
    "\n",
    "# Summary of our model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the head of the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training head...\n",
      "Epoch 1/10\n",
      "281/281 [==============================] - ETA: 0s - loss: 0.3219 - accuracy: 0.8635WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 70 batches). You may need to use the repeat() function when building your dataset.\n",
      "281/281 [==============================] - 277s 988ms/step - loss: 0.3219 - accuracy: 0.8635 - val_loss: 0.1668 - val_accuracy: 0.9414\n",
      "Epoch 2/10\n",
      "281/281 [==============================] - 262s 931ms/step - loss: 0.1929 - accuracy: 0.9308\n",
      "Epoch 3/10\n",
      "281/281 [==============================] - 272s 968ms/step - loss: 0.1844 - accuracy: 0.9312\n",
      "Epoch 4/10\n",
      "281/281 [==============================] - 266s 948ms/step - loss: 0.1808 - accuracy: 0.9340\n",
      "Epoch 5/10\n",
      "281/281 [==============================] - 262s 931ms/step - loss: 0.1710 - accuracy: 0.9408\n",
      "Epoch 6/10\n",
      "281/281 [==============================] - 263s 934ms/step - loss: 0.1642 - accuracy: 0.9409\n",
      "Epoch 7/10\n",
      "281/281 [==============================] - 354s 1s/step - loss: 0.1652 - accuracy: 0.9401\n",
      "Epoch 8/10\n",
      "281/281 [==============================] - 378s 1s/step - loss: 0.1568 - accuracy: 0.9451\n",
      "Epoch 9/10\n",
      "281/281 [==============================] - 378s 1s/step - loss: 0.1466 - accuracy: 0.9477\n",
      "Epoch 10/10\n",
      "281/281 [==============================] - 376s 1s/step - loss: 0.1422 - accuracy: 0.9487\n"
     ]
    }
   ],
   "source": [
    "BS = 32\n",
    "\n",
    "print(\"[INFO] training head...\")\n",
    "\n",
    "H = model.fit(\n",
    "    aug.flow(x_train, y_train, batch_size=BS),\n",
    "\tsteps_per_epoch=len(x_train) // BS,\n",
    "\n",
    "\tvalidation_data=(x_validation, y_validation),\n",
    "\tvalidation_steps=len(x_validation) // BS,\n",
    "\tepochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.32194966077804565,\n",
       "  0.19289517402648926,\n",
       "  0.1843528300523758,\n",
       "  0.18084090948104858,\n",
       "  0.17104454338550568,\n",
       "  0.164242222905159,\n",
       "  0.16524559259414673,\n",
       "  0.15682485699653625,\n",
       "  0.14657250046730042,\n",
       "  0.14223794639110565],\n",
       " 'accuracy': [0.8634591698646545,\n",
       "  0.9308386445045471,\n",
       "  0.9311727285385132,\n",
       "  0.933957040309906,\n",
       "  0.9407506585121155,\n",
       "  0.9408619999885559,\n",
       "  0.9400824308395386,\n",
       "  0.945094108581543,\n",
       "  0.9476556181907654,\n",
       "  0.9486579895019531],\n",
       " 'val_loss': [0.16682837903499603],\n",
       " 'val_accuracy': [0.9414114356040955]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e88401b6d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de1wU5f4H8M/sLuxyVdiFRW5eyBuaF0RRNBUhTmkallqWlqEe0zqWv7Kk8JBHUbPMW1qmqGV28pRmN+0oimlRSSrmJQ0UOSgosAtyv+zO8/tjYWBggQVhF5fv+/Xa1+7MPM/Mdx9xvjvPXB6OMcZACCGEAJBYOgBCCCHtByUFQgghAkoKhBBCBJQUCCGECCgpEEIIEVBSIIQQIqCkQEx2/PhxcByHGzduNKsex3H49NNP2yiqjmvs2LGYM2eOpcMgVoaSghXiOK7RV7du3Vq03uDgYGRlZcHT07NZ9bKysjBlypQWbbO5KAEZ9+KLL0IqlWLjxo2WDoW0c5QUrFBWVpbw+vrrrwEAp06dEuYlJSWJyldUVJi0XltbW3h4eEAiad6fjYeHBxQKRbPqkNZTUlKCTz/9FG+88QY++ugjS4cDwPS/OWJ+lBSskIeHh/BydXUFALi5uQnz3N3dsXHjRjz11FPo1KkTnn76aQDAm2++ib59+8Le3h4+Pj54/vnncefOHWG9dbuPqqePHDmC0aNHw97eHv7+/vjvf/8riqfur3eO47BlyxbMnDkTTk5O8PHxwZo1a0R1NBoNpk6dCgcHB6jVaixduhTPPvsswsLC7qptPv74Y/j7+0Mul8Pb2xvR0dHQ6XTC8p9++gkjR46Ek5MTnJycMHDgQNH3WblyJXr06AG5XA43Nzf87W9/Q2lpaYPb++yzzxAUFIROnTpBpVJhwoQJ+Ouvv4Tl169fB8dx+M9//oOJEyfC3t4ePXr0wO7du0XrSU9Px0MPPQQ7Ozv4+vpi06ZNJn/nvXv3ws/PD9HR0cjMzERiYqLRMkOGDIFCoYBSqcTDDz+MvLw8YfnmzZuFdnN3dxcd+XXr1g0rVqwQrW/OnDkYO3asMD127FjMnj0bS5cuRZcuXeDl5WVS+wBAdnY2nnvuOajVaigUCvTu3Rs7duwAz/Po0aMHVq5cKSpfXFwMZ2dn7Nq1y+Q2IjUoKXRQy5Ytw4gRI3DmzBnExsYCAOzs7PDRRx/h0qVL2LVrF44fP46FCxc2ua5XX30Vb7zxBs6dO4fAwEA88cQTyM/Pb3L7o0ePRnJyMhYvXozXX38dCQkJwvLnnnsO586dw3fffYdjx47hxo0bOHDgwF195++//x6RkZGYOXMmzp8/j7Vr12Lz5s1YtmwZAECv12PSpEkICgrCmTNncObMGbz11luwt7cHAOzfvx+rV6/Ghg0bkJKSgiNHjuDhhx9udJvl5eVYunQpzpw5gyNHjkAqlWLChAn1fikvWbIEM2fOxB9//IFp06bhueeeQ0pKCgCAMYbJkydDo9Hg+PHj+Oabb/DNN9/gzJkzJn3vrVu34tlnn4VcLseTTz5Z72hh586dmDFjBiIiInDmzBkkJCTgoYcegl6vBwDExMTg9ddfx4IFC3D+/Hn88MMPGDRokEnbru0///kPcnJycPToURw7dsyk9iktLcWYMWNw7tw57NmzB5cuXcKmTZtgb28PiUSCuXPnIi4uDrWf1vP5559DIpFg2rRpzY6RAGDEqp08eZIBYGlpacI8ACwyMrLJuvv372e2trZMr9czxhhLSEhgAFhGRoZoet++fUKdrKwsBoD98MMPou3t3r1bNP2Pf/xDtK3evXuzJUuWMMYY++uvvxgAFh8fLyyvqKhg3t7eLDQ0tNGY626rtlGjRrGpU6eK5q1fv54pFApWXl7OtFotA8ASEhKM1n/vvfdYz549WUVFRaMxNEaj0TAA7KeffmKMMZaWlsYAsLVr1wplKisrmYODA/vwww8ZY4wdOXKEAWBXrlwRymRnZzOFQsFmz57d6PaSk5OZjY0Ny87OZowx9ttvvzE7OzuWl5cnlPHx8WEvvPCC0fpFRUVMoVCwd955p8FtdO3alS1fvlw0b/bs2WzMmDHC9JgxY1jPnj2Fv6WG1G2f7du3M7lcLvzN1XXr1i1mY2PDjhw5IswbPnw4W7BgQaPbIQ2jI4UOatiwYfXm7d+/H6NHj4anpyccHR3x9NNPo6KiArdu3Wp0XbV/NXp4eEAqleL27dsm1wEALy8voc6lS5cAAMOHDxeW29jYIDAwsPEv1YSLFy9i9OjRonljxoxBWVkZrl69ChcXF8yZMwd/+9vf8PDDD2P16tW4cuWKUHbatGmorKxE165dMWvWLOzevRuFhYWNbjM5ORmTJ09G9+7d4eTkBF9fXwCG7qDaareHTCaDWq0WtYdKpUKvXr2EMm5ubujdu3eT33nr1q0YP3483NzcABj+3bt37y5052VnZyMjIwPh4eFG61+8eBFlZWUNLm+OIUOG1Dsf1VT7nD59Gv7+/vD29ja6TrVajUcffRTbtm0T4v31118xd+7cu463o6Kk0EE5ODiIpn/77TdMnToVo0ePxldffYUzZ87gww8/BND0SUFbW9t683ieb1YdjuPq1eE4rtF1tETddbKqbofq+du2bcPp06fx4IMP4scff0T//v2xdetWAIbEdfnyZezYsQPu7u5Yvnw5evfujYyMDKPbKikpQXh4ODiOw44dO3Dq1CkkJSWB47h6bdpYezDGWtQWxcXF2LNnD7755hvIZDLh9eeff9brQmpq/Y0tl0gkou4bAKisrKxXru7fnKnt01Rszz//PA4cOICcnBxs27YNQ4cObVH3FjGgpEAAGE6wqlQqrFixAkFBQejVq1ez70doLf7+/gCAX375RZin0+lw+vTpu1pvv3798OOPP4rmnThxAnZ2dujRo4cwr3///vi///s/HDp0CLNnzxbtQOVyOR566CGsWbMG58+fR0lJSYPnOv7880/k5OQgNjYWISEh6Nu3L/Ly8urtQE2JOycnRzjHAAC5ubn1TsjW9fnnn0MqleLcuXNITk4WXidPnhR+Ubu7u8Pb27vexQHV/P39oVAoGlwOAO7u7sjMzBTNO3v2bJPfy5T2GTJkCC5evNjo3+K4cePg6+uLjz76CLt376ajhLsks3QApH3o3bs3cnJyEBcXh5CQEPz000/YsmWLRWLp2bMnJk6ciBdeeAFbt26Fm5sb1q5di4KCApN+Mf/vf/9DcnKyaJ6npyeioqIwceJErF69Go899hiSk5Px1ltv4ZVXXoGtrS1SU1Oxbds2TJw4ET4+PsjMzMTJkycREBAAAIiLiwPP8xg2bBg6d+6Mo0ePorCwUEhidXXt2hVyuRybNm3CK6+8guvXr2PJkiXN/tUfGhqKgQMHYsaMGdi0aRNsbW3x+uuvQyZr/L/v1q1bMXnyZNx///31lo0cORIfffQRhg8fjpiYGMyfPx9qtRpTpkwBz/NISEjAk08+CZVKhVdeeQVvvfUW7Ozs8OCDD6K0tBQHDx5EVFQUACAsLAxbtmzB5MmT0bVrV3z44YdIT08XrnxriCntM336dKxZswaTJk3CmjVr4Ofnh2vXriE3NxdPPPEEAMORxN///ndER0fD1tYW06dPb1b7kjosekaDtLmGTjQbOxkbHR3N3N3dmb29PXv44YfZZ599Jqrb0InmuicBpVIp27lzZ4PbM7b90NBQ9uyzzwrTubm57PHHH2d2dnbMzc2NLV26lE2ZMoU98sgjjX5fAEZfq1atYowxtmvXLtanTx9mY2PDPD092RtvvMEqKysZY4xlZmayyZMnMy8vL2Zra8u6dOnC5syZw/Lz8xljjO3bt4+NGDGCde7cmdnZ2bF+/fqx7du3NxrPF198we677z4ml8vZoEGD2PHjx0XtU32i+eTJk6J6fn5+LCYmRphOS0tjDz74IJPL5czLy4utX7+ejRkzpsETzWfPnq13wr+2999/n9nb2wvf7dNPP2UDBgxgtra2zNXVlY0fP144Gc3zPFu/fj3r1asXs7GxYe7u7mzKlCnCugoKCtiMGTNY586dmZubG4uJiTF6otlYrE21D2OGixdmzpzJlEolk8vlrHfv3qLljDGWk5PDbGxs2N///nej35eYjmOMRl4j7Z9er0efPn0wadIkrF271tLhkHbm0qVL6NevH37//XcMGTLE0uHc06j7iLRLJ06cQHZ2NgYPHozCwkKsW7cO169fx6xZsywdGmlHysvLcfPmTURFRWHMmDGUEFoBJQXSLun1eqxYsQKpqamwsbFB//79kZCQYLR/nHRc//73vxEZGYl+/frhyy+/tHQ4VoG6jwghhAjoklRCCCECSgqEEEIE9/w5hbo3zZhKpVIhNze3laO5d1F7iFF71KC2ELOG9mhsTBQ6UiCEECKgpEAIIURASYEQQoiAkgIhhBABJQVCCCECSgqEEEIElBQIIYQI7vn7FAghpLkYY+AZoOMZ9IxBzwN6nkHHGPS8Ybr2Zz1jhrI8g2OxFHcKioV1MAbwYGBVn1nVZ54ZntvOs6plVds1zKuqVzVdv17NuoV6DOBrxe7vbo/BXRwa+5otQkmBENKmGGOo5BnKdQwVeh4VeoZyHY9yfdW0jqG8an5Ty/TCTpxBV7WzFj4bWabjGXieQceqdvo8A88My+9lHIDJ/oySAiEtpeMZSit5lOl4lFbyKK31XlbnvVTHQy6/g9KyspoVGHlupLEnSZryeMnm1OM4ww4AACScYYYEADhD32/1KGUSrrqM4QNXXZcDJOCE8lUfwXFcTZna9bhadcGB4wCHmxXQ3ikU7bQr9Iadde0dfUWt6XI9Q0XVzr1Sz4x+Z1PYSjnIpRxspRLYSDlIJRxkHAepBIbPEg5SDlDIOMgkEkirpmvKVZXlqsrWXl5ruvqzrNbymjqG+tXLXTp3QkHBHUhqtaHESHvWbv/a7SosQ516Vf+2Qj3ROjlIuNr/Pq0/fnk1Sgqk3WHMsPMR7aib2qFXz6vkUapjoh18aSUPHW/abokDoJBJIJMWgjG+3rL6FerPNVau3jwjhYzVq+laqOl6QK2uCSbqfqhVBoYyrU3CAXKpBLYyzvAu5SCXGXbadjIJOimq5gnLak3XqiOuLy5jK5VALuVgI+WEZNWeqFSdkCuvtHQYbYaSggXpeYac4krhP2/1/2EGJkywWvNF82r9tBTq1doJ1J5X93caY/V/rWZWFECTVywchlf3nxr6XA2/tEXz+FrzWO1lqPnMjMwTytdsp6Y8UFG1Izd1hyaTAHYyCRQyCexsat5d7GwMn6um7eosV9SZbyeTQGFj2BlxHGcVz7cBjCWNmr7rhqfF9ZSurigqyIOtVAKZpP3tpEnroqRgATqe4XjaHXx5UYOswnv7F4eEq31oXXNYLhMOv+vMk3CwrXUoXnPYbliPXNbwDrtmx87BzkYKOxkHGyldQNeY6m4i8WFI83bsrg624EulrRgVac8oKZhRpZ7H0Wt3sO+iFtnFlejhIsf8YWooZIYdm7G+wuo+xerP1R844SNnZF7D5WqvXljGAZ06dUJJUYHQDyv0t0oAGwlXr4+2eqcvpV+OhFgVSgpmUK7jceRqPvZf1EJTqkMvpQLzhqoxxNOhTU8YNYdK5YLcXL2lwyCEWBglhTZUpuPxQ0oevrqkRX6ZHv5udlg4ogsGeti3m2RACCG1UVJoAyWVehy8ko+vL2tRUK7HAA97LO6vQn+1vaVDI4SQRpktKSQnJ2Pnzp3geR6hoaGIiIgQLS8qKsIHH3yA27dvw8bGBvPnz4evr6+5wmsVReV6fHclD99e0aKogscQTwdM669CHzc7S4dGCCEmMUtS4HkecXFxiI6OhlKpRFRUFAIDA+Ht7S2U+eqrr9CtWzcsXrwYN2/eRFxcHP75z3+aI7y7VlCmw9eX8/D9lTyU6ngEeTtian8leiopGRBC7i1mSQqpqanw8PCAWq0GAAQHByMpKUmUFG7cuIHJkycDALy8vJCTk4P8/Hx07tzZHCG2SF6pDgf+1OKHlDyU6xiCfZ0wtb8S3V0Ulg6NEEJaxCxJQavVQqlUCtNKpRIpKSmiMl27dsVvv/2GPn36IDU1FTk5OdBqtfWSQnx8POLj4wEAq1evhkqlalFMMpmsxXVzisqx5/QNfH3+NnQ8j7BebnhmqA+6K+/dcwZ30x7WiNqjBrWFmLW3h1mSAjPyYJe6V99ERERg165dWLx4MXx9fdG9e3dIJPVvTAoLC0NYWJgw3dK7Tltyx2p2USX2XdIg/uodMMYwtnsnTOmnhKezLcBKkJtb0qJY2gNruYO3tVB71KC2ELOG9vD09GxwmVmSglKphEajEaY1Gg1cXFxEZezt7bFgwQIAhiTy4osvwt3d3RzhNSmrsAJfXtQg4dodcBwQ2qMzHu/nCrWjraVDI4SQVmWWpODn54esrCxkZ2fD1dUViYmJWLhwoahMcXEx5HI5ZDIZjh49ir59+8Le3rLdMTfulOOLCxqcSC+AlOPwUM/OmOyvhJuDjUXjIoSQtmKWpCCVShEZGYnY2FjwPI+QkBD4+Pjg8OHDAIDw8HDcvHkT77//PiQSCby9vfH888+bIzSjrueV4T8XNEj8XyFspRwm9nZBhL8SrnZ0WwchxLpxzFiH/z0kMzOzRfWM9Qte1ZZh7/lc/HajCAqZBBN6dcajfV3RSWH9ycAa+klbE7VHDWoLMWtoD4ufU2jvruSWYu/5XJzOLIaDjQRP3K/ExN6ucJLTkyEJIR1Lh04KF2+XYO+FXJy7VQInWwmeHqjChF4ucLClZEAI6Zg6ZFJI0ZQi5vgfSL5ZgE4KKZ4d7IaHe7rAzoaezU8I6dg6ZFKo0DPcyC/DnCHuCL+vM+QySgaEEAJ00KTQz90eXz4XiDt5WkuHQggh7UqH/YlMwzgSQkh9tGckhBAioKRACCFEQEmBEEKIgJICIYQQASUFQgghAkoKhBBCBJQUCCGECCgpEEIIEVBSIIQQIqCkQAghRGC2Zx8lJydj586d4HkeoaGhiIiIEC0vKSnBxo0bodFooNfrMXHiRISEhJgrPEIIITBTUuB5HnFxcYiOjoZSqURUVBQCAwPh7e0tlPnhhx/g7e2NJUuWoKCgAC+99BIeeOAByGQd8pl9hBBiEWbpPkpNTYWHhwfUajVkMhmCg4ORlJQkKsNxHMrKysAYQ1lZGRwdHSGRUO8WIYSYk1l+hmu1WiiVSmFaqVQiJSVFVOahhx7CmjVrMG/ePJSWlmLRokVGk0J8fDzi4+MBAKtXr4ZKpWpRTDKZrMV1rRG1hxi1Rw1qCzFrbw+zJAXGWL15HMeJps+dO4euXbvin//8J27fvo3ly5ejT58+sLe3F5ULCwtDWFiYMN3SAbStYfDt1kTtIUbtUYPaQswa2sPT07PBZWbpn1EqldBoNMK0RqOBi4uLqExCQgKCgoLAcRw8PDzg7u6OzMxMc4RHCCGkilmSgp+fH7KyspCdnQ2dTofExEQEBgaKyqhUKpw/fx4AkJ+fj8zMTLi7u5sjPEIIIVXM0n0klUoRGRmJ2NhY8DyPkJAQ+Pj44PDhwwCA8PBwPP7449iyZQteeeUVAMDTTz8NZ2dnc4RHCCGkCseMdfjfQ1raxWQN/YKtidpDjNqjBrWFmDW0h8XPKRBCCLk3UFIghBAioKRACCFEQEmBEEKIgJICIYQQASUFQgghAkoKhBBCBJQUCCGECCgpEEIIEVBSIIQQIqCkQAghREBJgRBCiICSAiGEEAElBUIIIQJKCoQQQgRmGWQHAJKTk7Fz507wPI/Q0FBERESIln/zzTc4efIkAIDnedy4cQNxcXFwdHQ0V4iEENLhmSUp8DyPuLg4REdHQ6lUIioqCoGBgfD29hbKTJo0CZMmTQIA/P777/j+++8pIRBCiJmZ3H308ccf4/r16y3aSGpqKjw8PKBWqyGTyRAcHIykpKQGy//8888YOXJki7ZFCCGk5Uw+UtDr9YiNjYWzszMeeOABPPDAA1AqlSbV1Wq1orJKpRIpKSlGy5aXlyM5ORmzZ882ujw+Ph7x8fEAgNWrV0OlUpn6FURkMlmL61ojag8xao8a1BZi1t4eJieFyMhIzJo1C2fPnsXJkyexf/9+9OzZE6NHj0ZQUBAUCkWDdY0NA81xnNGyp0+fRu/evRvsOgoLC0NYWJgw3dKxUq1hnNXWRO0hRu1Rg9pCzBrao7Exmpt1TkEikWDIkCEYMmQIMjIysHHjRmzZsgXbt2/HyJEjMW3aNLi6utarp1QqodFohGmNRgMXFxej2/j5558xatSo5oRFCCGklTTrktSSkhIcO3YMy5YtQ0xMDO677z4sW7YM69atg0KhwMqVK43W8/PzQ1ZWFrKzs6HT6ZCYmIjAwECj67906ZLRZYQQQtqeyUcKa9euxblz59C3b188+OCDGDp0KGxsbITlzzzzDGbNmmW0rlQqRWRkJGJjY8HzPEJCQuDj44PDhw8DAMLDwwEAp06dwsCBAxvtiiKEENJ2OGasw9+Ib775BqNHj0bnzp0bLFNeXg65XN5qwZkiMzOzRfWsoV+wNVF7iFF71KC2ELOG9mjsnILJ3UcDBgyATqcTzcvNzRVdpmruhEAIIaR1mZwUNm3aBL1eL5qn0+nw/vvvt3pQhBBCLMPkpJCbmwu1Wi2a5+HhgZycnFYPihBCiGWYnBRcXV1x7do10bxr1641eGkpIYSQe4/JVx9NmDAB77zzDiZNmgS1Wo3bt2/j22+/xWOPPdaW8RFCCDEjk5NCWFgYHBwccOzYMWg0GiiVSjzzzDMYPnx4W8ZHCCHEjJp1R/OIESMwYsSItoqFEEKIhTUrKeTn5yM1NRWFhYWi5xmNGzeu1QMjhBBifiYnhVOnTmHTpk3o0qULMjIy4OPjg4yMDPTp04eSAiGEWAmTk8LevXuxYMECjBgxAs899xzWrFmDhIQEZGRktGV8hBBCzKhZ9ynUPZ8wZswYnDhxotWDIoQQYhkmJwVnZ2fk5+cDANzc3PDXX3/h9u3b4Hm+zYIjhBBiXiZ3H4WGhuLy5csYPnw4JkyYgGXLloHjODzyyCNtGR8hhBAzMjkpTJo0CRKJ4cBizJgx6NevH8rKyuDt7d1mwRFCCDEvk7qPeJ7HzJkzUVlZKcxTqVSUEAghxMqYlBQkEgk8PT1RWFjY1vEQQgixIJO7j0aNGoW3334bDz/8MJRKJTiOE5b179+/yfrJycnYuXMneJ5HaGgoIiIi6pW5ePEidu3aBb1eDycnJyxbtszU8AghhLQCk5NC9dCZX3zxhWg+x3FNjqnA8zzi4uIQHR0NpVKJqKgoBAYGirqfiouLsX37drz55ptQqVS4c+dOc74HIYSQVmByUti8eXOLN5KamgoPDw9hPIbg4GAkJSWJksJPP/2EoKAgqFQqAECnTp1avD1CCCEt06xnH7WUVquFUqkUppVKJVJSUkRlsrKyoNPp8NZbb6G0tBTjx4/HmDFj6q0rPj4e8fHxAIDVq1cLSaS5ZDJZi+taI2oPMWqPGtQWYtbeHiYnhfnz5ze47IMPPmi0bu2H51WrfU4CAPR6PdLS0rB06VJUVFQgOjoaPXv2rDfAdFhYGMLCwoTplg6gbQ2Db7cmag8xao8a1BZi1tAedfertZmcFP7xj3+IpvPy8nDw4EGMHDmyybpKpRIajUaY1mg09UZsUyqVcHJygkKhgEKhQN++fZGent5o8IQQQlqXyY+58Pf3F71GjhyJxYsXIyEhocm6fn5+yMrKQnZ2NnQ6HRITExEYGCgqExgYiMuXL0Ov16O8vBypqanw8vJq/jcihBDSYnd1TkEmkyE7O7vJclKpFJGRkYiNjQXP8wgJCYGPj49wRVN4eDi8vb0xaNAgvPrqq5BIJBg3bhx8fX3vJjxCCCHN1KxHZ9dWXl6Os2fPYvDgwSbVDwgIQEBAgGheeHi4aHrSpEmYNGmSqSERQghpZSYnhdrnBABALpfjkUcewejRo1s9KEIIIZZhclJYsGBBW8ZBCCGkHTD5RPOBAweQmpoqmpeamoqvv/661YMihBBiGSYnhYMHD9Z7Kqq3tzcOHjzY6kERQgixDJOTgk6ng0wm7m2SyWSoqKho9aAIIYRYhslJoUePHvjvf/8rmnf48GH06NGj1YMihBBiGSafaH722WexYsUKnDhxAmq1Grdv30Z+fj6WLl3alvERQggxI5OTgo+PDzZs2IDTp09Do9EgKCgIQ4YMgUKhaMv4CCGEmJHJSUGr1cLW1lb0rKOioiJotVq4urq2SXCEEELMy+RzCu+88w60Wq1onlarxbvvvtvqQRFCCLEMk5NCZmZmvWcR+fr64ubNm60eFCGEEMswOSk4Ozvj1q1bonm3bt2Ck5NTqwdFCCHEMkw+pxASEoK1a9fiySefhFqtxq1bt7B3716MGzeuLeMjhBBiRiYnhYiICMhkMuzevRsajQZKpRLjxo3DxIkT2zI+QgghZmRyUpBIJPUebc3zPM6ePVvvkdiEEELuTS0aZCc9PR0//vgjfvrpJ/A8j+3btzdZJzk5GTt37gTP8wgNDUVERIRo+cWLF7FmzRq4u7sDAIKCgjBlypSWhEcIIaSFTE4KBQUFOHnyJH788Uekp6eD4zg899xzJp1T4HkecXFxiI6OhlKpRFRUFAIDA+s9YK9v375YsmRJ878FIYSQVtFkUvj1119x/PhxnDt3Dl5eXhg1ahQWL16MN998E8OHD4eNjU2TG0lNTYWHhwfUajUAIDg4GElJSfWSAiGEEMtqMimsW7cOjo6OWLRoEYYNG9aijWi1WiiVSmFaqVQiJSWlXrm//voLixcvhouLC2bOnAkfH596ZeLj4xEfHw8AWL16NVQqVYtikslkLa5rjag9xKg9alBbiFl7ezSZFObPn48ff/wR7733Hvz8/DBq1CgEBweD4ziTN8IYqzevbv3u3btjy5YtUCgUOHPmDN555x1s3LixXr2wsDCEhYUJ07m5uSbHUZtKpWpxXWtE7SFG7VGD2kLMGtrD09OzwWVN3rw2duxYxMTEYNOmTRg8eDB++OEHPP/88ygoKMDZs2fB83yTARvoY+gAAB3GSURBVCiVStEYzxqNBi4uLqIy9vb2wsP1AgICoNfrUVBQ0OS6CSGEtB6T72h2c3PDlClTsGHDBsTExGDs2LH4+OOPMX/+/Cbr+vn5ISsrC9nZ2dDpdEhMTERgYKCoTH5+vnBEkZqaCp7n6W5pQggxsya7j/744w/4+/uLRl3r06cP+vTpg8jISCQlJTW5EalUisjISMTGxoLneYSEhMDHxweHDx8GAISHh+PXX3/F4cOHIZVKYWtri5dffrlZXVSEEELuHseMdfjXEhsbi2vXrqF3794ICAhAQEBAu3pUdmZmZovqWUO/YGui9hCj9qhBbSFmDe3R2DmFJo8U3nzzTZSXl+P8+fM4e/YsvvrqK9jb22Pw4MEICAhAr169IJGY3AtFCCGkHTPp5jW5XI7AwEDhPMD//vc/nD17Fv/+97+RmZmJfv36YcKECejZs2ebBksIIaRttegxF76+vvD19cWjjz6KkpISnDt3DqWlpa0dGyGEEDMzOSlcuHAB7u7ucHd3R15eHvbs2QOpVIrp06djxIgRbRkjIYQQMzH5ZEBcXJxw7uCTTz6BXq8HAGzdurVtIiOEEGJ2Jh8paLVaqFQq6PV6nDt3Dlu2bIFMJsO8efPaMj5CCCFmZHJSsLOzQ35+PjIyMuDt7Q2FQgGdTgedTteW8RFCCDEjk5PCQw89hKioKOh0OsyaNQsAcPnyZXh5ebVVbIQQQsysWcNxDhs2DBKJBB4eHgAAV1dXPP/8820WHCGEEPNq1iWpte+Cu3DhAiQSCfz9/Vs9KEIIIZZh8tVHMTExuHz5MgDgwIED2LBhAzZs2ID9+/e3WXCEEELMy+SkkJGRgV69egEAjh49ipiYGMTGxuLIkSNtFhwhhBDzMrn7qPq5ebdu3QIAYSjN4uLiNgiLEEKIJZicFHr37o0dO3YgLy8PQ4cOBWBIEDTmASGEWA+Tu49eeOEF2Nvbo2vXrpg2bRoAw2Orx48f32bBEUIIMS+TjxScnJzw1FNPieYFBAS0ekCEEEIsx+SkoNPpsH//fpw4cQJ5eXlwcXHB6NGj8dhjj4lGZWtIcnIydu7cCZ7nERoaioiICKPlUlNT8eabb2LRokUYPny46d+EEELIXTM5KXz66ae4evUq5s6dCzc3N+Tk5GDfvn0oKSkR7nBuCM/ziIuLQ3R0NJRKJaKiohAYGCicrK5dbs+ePRg0aFCLvgwhhJC7Y/I5hV9//RWvvfYaBg4cCE9PTwwcOBCvvvoqfvnllybrpqamwsPDA2q1GjKZDMHBwUbHdj506BCCgoLg7OzcvG9BCCGkVTT7ktSW0Gq1UCqVwrRSqURKSkq9MqdOnUJMTAw++OCDBtcVHx+P+Ph4AMDq1auhUqlaFJNMJmtxXWtE7SFG7VGD2kLM2tvD5KQwYsQIvP3225gyZYowcPW+fftMGmDHWELhOE40vWvXLjz99NNNjvccFhaGsLAwYbqlA2hbw+DbrYnaQ4zaowa1hZg1tEftRxbVZXJSmDFjBvbt24e4uDjk5eXB1dUVwcHBJj06W6lUQqPRCNMajQYuLi6iMlevXsWGDRsAAAUFBTh79iwkEgmGDRtmaoiEEELukslJQSaT4YknnsATTzwhzKuoqMDMmTMxY8aMRuv6+fkhKysL2dnZcHV1RWJiIhYuXCgqs3nzZtHnIUOGUEIghBAza9ZTUuuq2wXUEKlUisjISMTGxoLneYSEhMDHxweHDx8GAISHh99NGIQQQlrJXSWF5ggICKh3s1tDyeCFF14wR0iEEELqaDIpXLhwocFlNBQnIYRYlyaTQmOXhwKw6kuzCCGko2kyKdQ+AUwIIcS6mXxHMyGEEOtHSYEQQoiAkgIhhBABJQVCCCECSgqEEEIElBQIIYQIKCkQQggRUFIghBAi6LBJgZWXWToEQghpdzpkUmAXTiN3/lSwtJSmCxNCSAfSIZMC3D3B2crBr40Gu3Le0tEQQki70SGTAufeBS4rPwBcVeDXvwV27pSlQyKEkHbBbOMpJCcnY+fOneB5HqGhoYiIiBAtT0pKwt69e8FxHKRSKWbNmoU+ffq0WTxSVzdIXlsFfsMy8FtWgnvuZUiGj22z7RFCyL3ALEmB53nExcUhOjoaSqUSUVFRCAwMhLe3t1Dm/vvvR2BgIDiOQ3p6OtatW4f169e3aVycozMkrywH/34s2I514EtLIAkZ36bbJISQ9sws3Uepqanw8PCAWq2GTCZDcHAwkpKSRGUUCoUwvGd5ebnJQ33eLU5hD8lLMcCAoWCffQj+4BdgjJll24QQ0t6Y5UhBq9VCqVQK00qlEikp9a/8OXXqFD777DPcuXMHUVFRRtcVHx+P+Ph4AMDq1atbPMiPTCYT1WXR76Jg0wqUfbUbdoyH4zMLzJaY2oO67dHRUXvUoLYQs/b2MEtSMPbL29gOd9iwYRg2bBguXbqEvXv3YunSpfXKhIWFISwsTJjOzc1tUUwqlapeXfb0AnBSGUoO7EGpJgfcjPngJNIWrf9eY6w9OjJqjxrUFmLW0B6enp4NLjNL95FSqYRGoxGmNRoNXFxcGizv7++PW7duoaCgwBzhCTiJBNz0eeDGTwM7eRhs+3tgukqzxkAIIZZklqTg5+eHrKwsZGdnQ6fTITExEYGBgaIyt27dEo4orl27Bp1OBycnJ3OEJ8JxHCSTZ4Cb8hxY0knwm1eClZebPQ5CCLEEs3QfSaVSREZGIjY2FjzPIyQkBD4+Pjh8+DAAIDw8HL/++itOnDgBqVQKW1tbLFq0yKJ9+pK/TQZv7wC2ezP49TGQ/GMpOHsHi8VDCCHmwLF7/FKbzMzMFtUztV+QT/oJLO49wMsXkpeXgXPq1KLttXfW0E/amqg9alBbiFlDe1j8nMK9TDJ0FCQvvgncugF+zRIwbY6lQyKEkDZDScEEXP8hkLz8L+BOHvi3l4DdumnpkAghpE1QUjAR19MfkldjgcoKwxFDRpqlQyKEkFZntmcfmQtjDGVlZeB5vtET1bdv30Z5c68qUnUBe/M9sD/PAdf+AmcjB+fc+S4jbh/qtgdjDBKJRHSnOSHE+lldUigrK4ONjQ1kssa/mkwmg1TaghvT7O3Bho8BbmcC5aUA1xmcnX0Lo20/jLWHTqdDWVkZ7OzsLBQVIcTcrK77iOf5JhPC3eJkNoCHF2BjA2RnghUXten2LEUmk4HneUuHQQgxI6tLCmZ7kJ5UBqi9AFsFkHMLrNC8d1+bC3UdEdKxWF1SMCdOKgXUnoCdHaC5DXYnz9IhEULIXaGkcJc4iQRw6wLYOwJ5uWD5Gnr0NiHknkVJoRUYEoMH4OiMOxnp+HjL5mYnhpkzZ+LOnTvN3vbLL7+M7777rtn1CCHEGKu7+qg2/vNtDd5PwHNci37Rcz7dIXlybv35HAemdEdBVhY++fe/8ey0qWAqd6FPXq/XN3q10+7du5sdCyGEtDarTgrmxnEcVm3ZiuuZWQifMhU2tnLYd+oEtVqNixcv4vjx44iMjERmZibKy8sxe/ZszJgxAwAQFBSEQ4cOobi4GDNmzMCwYcPw+++/w8PDAzt27DDpstCTJ09i+fLl0Ov1GDhwIFatWgW5XI6VK1fi8OHDkMlkGD16NP75z3/i22+/xbp16yCRSODs7IxvvvmmrZuHEHIPsOqkYOwXfTWZTAadTtfq23zjjTdw5coVHD6wH4nxh/Hs4igcPRqPrt26AwDWrl0LFxcXlJaWYsKECRg/fjxcXV1F60hLS8PmzZvxzjvvYN68eTh48CAef/zxRrdbVlaGRYsWYe/evfDz88PChQvxySefYMqUKTh06BBOnDgBjuOELqr169djz5496NKlS4u6rQgh1onOKbQRzrkz0MkVg/z7wFcuA9PrAQA7duxAWFgYJk6ciMzMTKSl1e/e8vHxQf/+/QEAAwYMQEZGRpPbu3r1Knx9feHn5wcAmDp1Kn777Tc4OTlBLpfj1VdfxcGDB4UjjsDAQCxatAh79uyBvio2QgihpNCGODt72Dt3BirKgds38fPJkzh58iS+/fZbxMfHo3///kYftSGXy4XPUqnUpJ12Q+dHZDIZvv/+e4wfPx4//PADnn76aQDA22+/jddeew2ZmZkIDw+HVqtt4bckhFgTq+4+sgQHBwcUFdW6w1kqBdw9gZwsFP7vOjo5O8POzg6pqak4c+ZMq233vvvuQ0ZGBtLS0tC9e3fs27cPw4cPR3FxMUpLSxEaGoqAgACMGjUKAHD9+nUEBAQgICAAR44cQWZmJpydnVstHkLIvclsSSE5ORk7d+4Ez/MIDQ1FRESEaPnJkyfx9ddfAwAUCgXmzJmDbt26mSu8VuPq6oqhQ4di3LhxUCgUUKlU4OzswdReGBs0FLv3f4XQcePgd999CAgIaLXtKhQKvPfee5g3b55wonnmzJnIz89HZGQkysvLwRhDTEwMAGDFihVIS0sDYwyjRo1Cv379qBuJEGKekdd4nsdLL72E6OhoKJVKREVF4aWXXoK3t7dQ5sqVK/Dy8oKjoyPOnj2LL774AitXrmxy3XVHXispKYG9fdMPqGurE82NYRXlhgfpMQaoPcHJFWbdfmMaag9T29PaWMPoWq2F2kLMGtrD4iOvpaamwsPDA2q1GjKZDMHBwUhKShKV6d27NxwdHQEAPXv2hEajMUdoZsXZyg0P0pNIgNs3wcpKLB0SIYSImKX7SKvVQqlUCtNKpRIpKSkNlj927BgGDx5sdFl8fDzi4+MBAKtXr4ZKpRItv337tslPSW3rp6k2sFEw767QZ2aA3c6CxM0DnFwOSKSAVAJwEqMPoVuyZAlOnTolmjd37lxMnz69FUOr3x5yubxeG3cEMpmsQ35vY6gtxKy9PcyyVzTWQ9XQ0zcvXLiAhIQE/Otf/zK6PCwsDGFhYcJ03cO48vJyk8ZJsET3UQ0OTO0FZGdCn51ZbxkkklovKSCRYPnL/6g3DxIJKosKAE4qqtOSJ5s21B7l5eX3/KFyS1hDF0FrobYQs4b2aKz7yCxJQalUirqDNBoNXFxc6pVLT0/H1q1bERUVBScnJ3OEZjGcVGpIDOVlAM8DvL7qnRdPMx7QVYrnNb5mMFFSqZ9IhM9czXLG24DpeYDjar0avtSVEGKdzJIU/Pz8kJWVhezsbLi6uiIxMRELFy4UlcnNzcW7776LF198sdEsZk04iQRo5qhtjLH6iaM6edRLLlWfdTqAr6iZZ0RDx0zs6l/QfxkHyGwAmczwLpUZBhiq/bnWO1e7bFPvQj0bcDYyQG4HODgBjk6Gd1s5jelAiBmZJSlIpVJERkYiNjYWPM8jJCQEPj4+OHz4MAAgPDwcX375JYqKirB9+3ahzurVq80R3j2F4zjDvQ9SKQCbZtcXJ5XqZKKHlOMMl6QyJn55dwUX9qjhaEWnE72z6mm9DqisNNykV1kJptfVKV/rcyNHHkaXyGSG5GDvKCQLzsFRNI+rTiDV8x0cAbkdJRNCWsAsl6S2pXvpktT2zByXpAoJyUiCEd7LSoDiQsMQp8WFQNU7q/XZ8F4AVFQ0vDGpTJwkHJzA2TvWHIFUzxPKVL0UhmRiDf3GrYXaQswa2sPi5xQ6kjt37uCrr77CrFmzmlVv5syZeP/999GpU6e2CawdEB3lyJsoa8L6WEU5UFJUkyyKqpJHSU3yYEWFhs+aHLCMa4ay5WU166i7UokEcHBCroMj9DJbQGFnSBRyhfAZcrtanxXgan2Gwh5QKIRynCWucCPkLlj1X+z2328jLa/M6DKuheMpdHdRYE6gusHlBQUF+OSTT+olBRpPofVxtnLAVg50rrnc2aRkUlkpOgpBSdWRSXUCKS6CDdNDX3AHKCsFCu+A5d4yfC4vM7zX+ttp9K9IJjOSSOwAhQJc1Xvd5Vx1grFVGE74M96wPZ6v1bXHGzZcvYzxAF+zjDWyTNxFWL3uhpcVOzqC1zPA3gGcvQNg5wBUv9s5ALa21FVnRaw6KVjCypUrkZ6ejgcffBA2Njawt7dv0/EU9uzZgz179qCiogLdu3fHxo0bYWdnh5ycHCxZsgTp6ekAgFWrVmHo0KH44osvsHXrVgBA3759sWnTJvM0TDvC2dgAnV0Nr+p5dcp0UqlQ2UAXAWPMcP6kvNSQIMqqEkV5KVhZmaELrDp51EokrKoMSouBfI1hunperUeMtLf+3FpP8jIem1RmuGCiTsIwJBB7UQIRJZXq5Qp7w0UXpF2gcwqtLCMjA88++yyOHTuGxMREPPPMMzh27Bh8fX0BAHl5eaLxFL788ku4urqKksLIkSNx8OBB9O/fH/PmzUN4eHiD4ylotVphPIa3334bbm5uiIyMxPPPP48hQ4Zg7ty50Ov1KC4uRlZWFubMmYOvv/4arq6uQiyNtQc95sI8WGVlrSRTlUjKSwFUXR4skVRdJiypc9mwBJBwdZZJDFmuelrSwmVV61a5uCD3RoYhmZUUA6XFYCXFQGlJ1XSR8JlVLa8uh9ISUXedURxnOEqyq5Uo7B3B2TnUSzaco3PN1WmOToC9k9m76OicArkrgwYNEhICYBhP4dChQwAgjKdQd5Cd5oyncOXKFaxZswYFBQUoLi7GmDFjAAA///wzNmzYAMBwJZezszO+/PJLTJgwQdiesXtFiGVwNjaGS3Md29+TajmFHbgmjqwaw3Q6w9FTnYQhTiyG+aw6kWhzwEquGz6Xlhi6stDAkYqdfc2FAo5O4Bycay4oqHrnHOvMo6vTGkRJoY3V/pWdmJgojKdgZ2eHKVOmmDSeQllZw7+0Fi1ahLi4OPTr1w979+7FL7/80mBZxhj9RyBmx8lkhmRXJ+GZ+pfIGDMcNQnnfQpqLiAQ3gsMFxkUFYJlZxnmlxbXrKPuSqsvda6bOETTTkDtBOPgBM6EpyXc6ygptLJ64ynUUlhYiE6dOrXqeApFRUVQq9WorKzEV199BQ8PDwDAqFGj8MknnwjdRyUlJRg1ahRmz56NuXPn1us+IqS94jiu6qoue0DpbphnQj2m11ddOFDYYDJhRQWG6duZYNeuGObrDd2oxo9KHJDj4Ai++qZLG9uqGzkN71z1tI2t4SWrVab2u6y6bJ3yDZU14485SgqtzNh4CtXGjh2L3bt3IywsDD169GiV8RQWL16MRx55BN7e3ujTp4+QkP71r3/htddew+effw6JRIJVq1YhMDAQCxcuxJQpUyCRSNC/f3+sX7/+rmMgpD3ipFLAubPhVT2viTrCUUmt5CEkjqp5tmAoLyoEq6ww3LRZWWHoHiusMJwbqqww3HNTe7mxbTXnyxhJLtwDf4MkPKLpus1EJ5oJADrRXJc1nExsLdQWYs1tD8aY4ebMygpAVytRCO8VwrQo0RgtWyvpDBgKyfCxLfoOdKKZEEIshOO4ql/4NgAcGi9rnpAaRUnhHvHGG2/UG5hozpw5eOKJJywUESHEGlldUrjHe8MaZMrQpG3BWtuTEGKc1d1GKJFI6FxBK9HpdJDQnaaEdChWd6SgUChQVlaG8vLyRi/jksvlRu8R6KjqtgdjDBKJBAqFwoJREULMzeqSAsdxDT4nqDa6okKM2oMQAlhh9xEhhJCWo6RACCFEQEmBEEKI4J6/o5kQQkjr6bBHCkuWLLF0CO0KtYcYtUcNagsxa2+PDpsUCCGE1EdJgRBCiKDDJoWwsDBLh9CuUHuIUXvUoLYQs/b2oBPNhBBCBB32SIEQQkh9lBQIIYQIrO7ZR6ZITk7Gzp07wfM8QkNDERHR+kPa3Styc3OxefNm5Ofng+M4hIWFYfz48ZYOy6J4nseSJUvg6upq9ZcfNqW4uBgffvghMjIywHEc5s+fj169elk6LIv47rvvcOzYMXAcBx8fHyxYsAC2traWDqvVdbikwPM84uLiEB0dDaVSiaioKAQGBsLb29vSoVmEVCrFzJkz0aNHD5SWlmLJkiUYMGBAh20PADh48CC8vLxQWlpq6VAsbufOnRg0aBBeeeUV6HS6DvtkYa1Wi0OHDmHdunWwtbXFe++9h8TERIwdO9bSobW6Dtd9lJqaCg8PD6jVashkMgQHB9cb0awjcXFxQY8ePQAAdnZ28PLyglartXBUlqPRaHDmzBmEhoZaOhSLKykpwZ9//olx48YBMIzj7eDQ+HCS1ozneVRUVECv16OiogIuLi6WDqlNdLgjBa1WC6VSKUwrlUqkpKRYMKL2Izs7G2lpabjvvvssHYrF7Nq1CzNmzKCjBBj+HpydnbFlyxakp6ejR48emDVrVoccY8PV1RUTJ07E/PnzYWtri4EDB2LgwIGWDqtNdLgjBWNX4DY2GE9HUVZWhrVr12LWrFmwt7e3dDgWcfr0aXTq1Ek4curo9Ho90tLSEB4ejjVr1kAul+PAgQOWDssiioqKkJSUhM2bN2Pr1q0oKyvDiRMnLB1Wm+hwSUGpVEKj0QjTGo3Gag8DTaXT6bB27Vo88MADCAoKsnQ4FnPlyhX8/vvveOGFF7B+/XpcuHABGzdutHRYFqNUKqFUKtGzZ08AwPDhw5GWlmbhqCzj/PnzcHd3h7OzM2QyGYKCgvDXX39ZOqw20eG6j/z8/JCVlYXs7Gy4uroiMTERCxcutHRYFsMYw4cffggvLy888sgjlg7Hop566ik89dRTAICLFy/i22+/7dB/G507d4ZSqURmZiY8PT1x/vz5DnsBgkqlQkpKCsrLy2Fra4vz58/Dz8/P0mG1iQ6XFKRSKSIjIxEbGwue5xESEgIfHx9Lh2UxV65cwYkTJ+Dr64vFixcDAKZPn46AgAALR0bag8jISGzcuBE6nQ7u7u5YsGCBpUOyiJ49e2L48OF4/fXXIZVK0a1bN6t93AU95oIQQoigw51TIIQQ0jBKCoQQQgSUFAghhAgoKRBCCBFQUiCEECKgpECImUybNg23bt2ydBiENKrD3adACAC88MILyM/Ph0RS87to7NixmD17tgWjMu6///0vtFotpk+fjpiYGERGRqJr166WDotYKUoKpMN6/fXXMWDAAEuH0aRr164hICAAPM/jxo0bHfauYmIelBQIqeP48eM4evQounfvjh9//BEuLi6YPXs27r//fgCGJ+1u27YNly9fhqOjIx599FHh7lae53HgwAEkJCTgzp076NKlCxYvXgyVSgUA+OOPP7By5UoUFhZi5MiRmD17dpMPZLx27RqmTJmCzMxMuLu7QyqVtm0DkA6NkgIhRqSkpCAoKAhxcXE4deoU3n33XWzevBmOjo7YsGEDfHx8sHXrVmRmZmL58uVQq9W4//778d133+Hnn39GVFQUunTpgvT0dMjlcmG9Z86cwapVq1BaWorXX38dgYGBGDRoUL3tV1ZWYu7cuWCMoaysDIsXL4ZOpwPP85g1axYmTZqExx57zJxNQjoISgqkw3rnnXdEv7pnzJgh/OLv1KkTJkyYAI7jEBwcjG+//RZnzpyBv78/Ll++jCVLlsDW1hbdunVDaGgoTpw4gfvvvx9Hjx7FjBkz4OnpCQDo1q2baJsRERFwcHCAg4MD+vXrh+vXrxtNCjY2Nti1axeOHj2KjIwMzJo1CytWrMCTTz7Zoce7IG2PkgLpsBYvXtzgOQVXV1dRt46bmxu0Wi3y8vLg6OgIOzs7YZlKpcLVq1cBGB7FrlarG9xm586dhc9yuRxlZWVGy61fvx7JyckoLy+HjY0NEhISUFZWhtTUVHTp0gWrVq1q1nclxFSUFAgxQqvVgjEmJIbc3FwEBgbCxcUFRUVFKC0tFRJDbm4uXF1dARjGILh9+zZ8fX3vavsvv/wyeJ7H3//+d3z00Uc4ffo0fvnllw79KG9iHnSfAiFG3LlzB4cOHYJOp8Mvv/yCmzdvYvDgwVCpVOjduzc+++wzVFRUID09HQkJCXjggQcAAKGhodi7dy+ysrLAGEN6ejoKCwtbFMPNmzehVqshkUiQlpZmtc/vJ+0LHSmQDuvtt98W3acwYMAAYUyJnj17IisrC7Nnz0bnzp3xf//3f3BycgIAvPTSS9i2bRvmzZsHR0dHTJ06VeiGeuSRR1BZWYkVK1agsLAQXl5eePXVV1sU37Vr19C9e3fh86OPPno3X5cQk9B4CoTUUX1J6vLlyy0dCiFmR91HhBBCBJQUCCGECKj7iBBCiICOFAghhAgoKRBCCBFQUiCEECKgpEAIIURASYEQQojg/wH7yVP12L7+9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = epochs\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "#plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "#plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "#plt.savefig(args[\"plot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   with_mask       0.97      0.96      0.97      1160\n",
      "without_mask       0.96      0.97      0.96      1093\n",
      "\n",
      "    accuracy                           0.97      2253\n",
      "   macro avg       0.97      0.97      0.97      2253\n",
      "weighted avg       0.97      0.97      0.97      2253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the testing set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(x_validation, batch_size=BS)\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(y_validation.argmax(axis=1), predIdxs,\n",
    "\ttarget_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\perro\\Documents\\deep_learning_final\\face_mask_detection\n",
      "Saved trained model at C:\\Users\\perro\\Documents\\deep_learning_final\\face_mask_detection\\final.h5 \n"
     ]
    }
   ],
   "source": [
    "# saving the model\n",
    "save_dir = path\n",
    "model_name = '\\\\final.h5'\n",
    "model_path = save_dir + model_name\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_4.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_5.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename  label\n",
       "0  Image_1.jpg    NaN\n",
       "1  Image_2.jpg    NaN\n",
       "2  Image_3.jpg    NaN\n",
       "3  Image_4.jpg    NaN\n",
       "4  Image_5.jpg    NaN"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_path = path + '\\\\Testing_set_face_mask.csv'\n",
    "test_image_order = pd.read_csv(test_set_path)\n",
    "test_image_order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Image_1.jpg', 'C:\\\\Users\\\\perro\\\\Documents\\\\deep_learning_final\\\\face_mask_detection//test//Image_1.jpg']\n"
     ]
    }
   ],
   "source": [
    "file_paths = [[fname, path+ '//test//' + fname] for fname in test_image_order['filename']]\n",
    "print(file_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels i.e.  1536 matches the number of filenames i.e.  1536\n"
     ]
    }
   ],
   "source": [
    "# Confirm if number of images is same as number of labels given\n",
    "if len(test_image_order) == len(file_paths):\n",
    "    print('Number of labels i.e. ', len(test_image_order), 'matches the number of filenames i.e. ', len(file_paths))\n",
    "else:\n",
    "    print('Number of labels does not match the number of filenames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>filepaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_1.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_2.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_3.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_4.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_5.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename                                          filepaths\n",
       "0  Image_1.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...\n",
       "1  Image_2.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...\n",
       "2  Image_3.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...\n",
       "3  Image_4.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...\n",
       "4  Image_5.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the file_paths to dataframe\n",
    "test_images = pd.DataFrame(file_paths, columns=['filename', 'filepaths'])\n",
    "test_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>filepaths</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_1.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_2.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_3.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_4.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_5.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename                                          filepaths  label\n",
       "0  Image_1.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...    NaN\n",
       "1  Image_2.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...    NaN\n",
       "2  Image_3.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...    NaN\n",
       "3  Image_4.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...    NaN\n",
       "4  Image_5.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...    NaN"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.merge(test_images, test_image_order, how = 'inner', on = 'filename')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the label column...\n",
    "test_data.drop('label', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>filepaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_1.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_2.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_3.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_4.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_5.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename                                          filepaths\n",
       "0  Image_1.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...\n",
       "1  Image_2.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...\n",
       "2  Image_3.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...\n",
       "3  Image_4.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...\n",
       "4  Image_5.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e68387ee0dd944ab9a4ccc3ed54f57c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1536.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Image Resizing and converting them to array for test images of folder test\n",
    "\"\"\" \n",
    "TQDM is a progress bar library. \n",
    "Inserting tqdm (or python -m tqdm)between pipes will pass \n",
    "through all stdin to stdout while printing progress to stderr\n",
    "\"\"\"\n",
    "tst_images = []\n",
    "with tqdm(total=len(test_data)) as pbar:\n",
    "    for i, file_path in enumerate(test_data.filepaths.values):\n",
    "        \n",
    "        #read image\n",
    "        img = cv2.imread(file_path,1)\n",
    "        \n",
    "        #color order is changed\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        #resize\n",
    "        #converting images to square\n",
    "        if(img.shape[0] > img.shape[1]):\n",
    "            tile_size = (int(img.shape[1]*256/img.shape[0]),256)\n",
    "        else:\n",
    "            tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n",
    "\n",
    "        #centering the images\n",
    "        img = centering_image(cv2.resize(img, dsize=tile_size))\n",
    "\n",
    "        #out put 224*224px \n",
    "        img = img[16:240, 16:240]\n",
    "        tst_images.append(img)\n",
    "        pbar.update(1)\n",
    "\n",
    "tst_images = np.array(tst_images)\n",
    "tst_images = tst_images/255 # Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536, 224, 224, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(path + '\\\\final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = model.predict(tst_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "names= ['with_mask', 'without_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_names1 = []\n",
    "for i in range(0,1536):\n",
    "    real_names1.append(str(\"'\")+names[np.argmax(target[i])]+str(\"'\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'without_mask'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'with_mask'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'without_mask'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'without_mask'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'with_mask'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           target\n",
       "0  'without_mask'\n",
       "1     'with_mask'\n",
       "2  'without_mask'\n",
       "3  'without_mask'\n",
       "4     'with_mask'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pd = pd.DataFrame(real_names1)\n",
    "final_pd = final_pd.astype(str)\n",
    "final_pd.index= test_data.index\n",
    "final_pd.columns= ['target']\n",
    "final_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>filepaths</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_1.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "      <td>'without_mask'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_2.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "      <td>'with_mask'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_3.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "      <td>'without_mask'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_4.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "      <td>'without_mask'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_5.jpg</td>\n",
       "      <td>C:\\Users\\perro\\Documents\\deep_learning_final\\f...</td>\n",
       "      <td>'with_mask'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename                                          filepaths  \\\n",
       "0  Image_1.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...   \n",
       "1  Image_2.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...   \n",
       "2  Image_3.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...   \n",
       "3  Image_4.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...   \n",
       "4  Image_5.jpg  C:\\Users\\perro\\Documents\\deep_learning_final\\f...   \n",
       "\n",
       "            label  \n",
       "0  'without_mask'  \n",
       "1     'with_mask'  \n",
       "2  'without_mask'  \n",
       "3  'without_mask'  \n",
       "4     'with_mask'  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the prediction column\n",
    "test_data['label'] = real_names1\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as CSV file\n",
    "final_pd.to_csv(path + \"\\\\prediction.csv\",index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
